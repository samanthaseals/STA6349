---
title: "Beta-Binomial"
subtitle: "STA6990: Applied Bayesian Analysis"
execute:
  echo: true
  warning: false
  message: false
format: 
  revealjs:
    theme: uwf2
    embed-resources: true
    slide-number: false
    width: 1600
    height: 900
    df-print: paged
    html-math-method: katex
title-slide-attributes:
    data-background-image: /Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/title.png
    data-background-size: contain 
editor: source
pdf-separate-fragments: true
fig-align: center
---

## Introduction {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"} 

- Last week, we talked about creating posterior models for discrete priors (non-named distributions).

- This week, we will now introduce having a named distribution as a prior.

## Example {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"} 

- Consider the following scenario. 

    - "Michelle" has decided to run for president and you're her campaign manager for the state of Florida. 
    
    - As such, you've conducted 30 different polls throughout the election season. 
    
    - Though Michelle's support has hovered around 45%, she polled at around 35% in the dreariest days and around 55% in the best days on the campaign trail.
    
<center><img src="images/W07-L2-a.png"></center>  

## Example {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"} 

- Past polls provide prior information about $\pi$, the proportion of Floridians that currently support Michelle. 

    - In fact, we can reorganize this information into a formal prior probability model of $\pi$.

- In a previous problem, we assumed that $\pi$ could only be 0.2, 0.5, or 0.8, the corresponding chances of which were defined by a discrete probability model.

    - However, in the reality of Michelle's election support, $\pi \in [0, 1]$. 
    
- We can reflect this reality and conduct a more nuanced Bayesian analysis by constructing a continuous prior probability model of $\pi$.

## Example {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"} 

<center><img src="images/W07-L2-a.png"></center>  

- A reasonable prior is represented by the curve on the right. 

    - Notice that this curve preserves the overall information and variability in the past polls, i.e., Michelle's support, $\pi$ can be anywhere between 0 and 1, but is most likely around 0.45.

## Example {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}     
    
- Incorporating this more nuanced, continuous view of Michelle's support, $\pi$, will require some new tools. 

    - No matter if our parameter $\pi$ is continuous or discrete, the posterior model of $\pi$ will combine insights from the prior and data. 
    
    - $\pi$ isn’t the only variable of interest that lives on [0,1]. 
    
- Maybe we're interested in modeling the proportion of people that use public transit, the proportion of trains that are delayed, the proportion of people that prefer cats to dogs, etc. 

    - The Beta-Binomial model provides the tools we need to study the proportion of interest, $\pi$, in each of these settings.    
    
## Beta Prior {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

<center><img src="images/W07-L2-a.png"></center>  

- In building the Bayesian election model of Michelle's election support among Floridians, $\pi$, we begin with the prior. 

    - Our continuous prior probability model of $\pi$ is specified by the probability density function (pdf). 
    
- What values can $\pi$ take and which are more plausible than others?

## Beta Prior {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- Let $\pi$ be a random variable, where $\pi \in [0, 1]$. 

- The variability in $\pi$ may be captured by a Beta model with shape hyperparameters $\alpha > 0$ and $\beta > 0$,

    - **hyperparameter:** a parameter used in a prior model.
    
$$ \pi \sim \text{Beta}(\alpha, \beta), $$

- The beta model is as follows,

$$f(\pi) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha) \Gamma(\beta)} \pi^{\alpha-1} (1-\pi)^{\beta-1}, \ \pi \in [0, 1]$$

## Beta Prior {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- Let's explore the shape of the Beta:

::: {.panel-tabset}

## Code

```{r}
#| eval: false

library(bayesrules)
library(tidyverse)

plot_beta(1, 5) + theme_bw()
plot_beta(1, 2) + theme_bw()
plot_beta(3, 7) + theme_bw()
plot_beta(1, 1) + theme_bw()
```

## Beta(1, 5)

<center>
```{r}
#| echo: false
library(bayesrules)
library(tidyverse)

plot_beta(1, 5) + theme_bw()
```
</center>

## Beta(1, 2)

<center>
```{r}
#| echo: false
plot_beta(1, 2) + theme_bw()
```
</center>

## Beta(3, 7)

<center>
```{r}
#| echo: false
plot_beta(3, 7) + theme_bw()
```
</center>

## Beta(1, 1)

<center>
```{r}
#| echo: false
plot_beta(1, 1) + theme_bw()
```
</center>

:::

## Beta Prior {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- Your turn!

- Explore the following and report back:

    - How would you describe the typical behavior of a Beta($\alpha, \beta$) variable, $\pi$, when $\alpha=\beta$?
    
    - How would you describe the typical behavior of a Beta($\alpha, \beta$) variable, $\pi$, when $\alpha>\beta$?
    
    - How would you describe the typical behavior of a Beta($\alpha, \beta$) variable, $\pi$, when $\alpha<\beta$?
    
    - For which model is there greater variability in the plausible values of $\pi$, Beta(20, 20) or Beta(5, 5)?

## Tuning the Beta Prior {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- We can *tune* the shape hyperparameters ($\alpha$ and $\beta$) to reflect our prior information about Michelle's election support, $\pi$.

- In our example, we saw that she polled as low as 25 and as high as 65 percentage points, with an average of 45 percentage points.

    - We want our Beta($\alpha, \beta$) to have similar patterns.
    
    - We want to pick $\alpha$ and $\beta$ such that $\pi$ tends to be around 0.45.
    
$$
E[\pi] = \frac{\alpha}{\alpha+\beta} \approx 0.45
$$

- Using algebra, we can tune, and find

$$\alpha \approx \frac{9}{11} \beta$$

## Tuning the Beta Prior {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- Your turn!

    - Graph the following and determine which is best for the example.
    
        - Beta(9, 11)
        - Beta(27, 33)
        - Beta(45, 55)
        
- Recall, this is what we are going for:        

<center><img src="images/W07-L2-a.png"></center>  

## Tuning the Beta Prior {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- Your turn!

::: {.panel-tabset}

## Wanting

- Recall, this is what we are going for:        

<center><img src="images/W07-L2-a.png"></center> 

## Code

```{r}
#| eval: false

plot_beta(9, 11) + theme_bw()
plot_beta(27, 33) + theme_bw()
plot_beta(45, 55) + theme_bw()
```

## Beta(9, 11)

<center>
```{r}
#| echo: false
plot_beta(9, 11) + theme_bw()
```
</center>

## Beta(27, 33)

<center>
```{r}
#| echo: false
plot_beta(27, 33) + theme_bw()
```
</center>

## Beta(45, 55)

<center>
```{r}
#| echo: false
plot_beta(45, 55) + theme_bw()
```
</center>

:::

## The Binomial Data Model and Likelihood Function {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}
        
- Now we are ready to think about the data collection.

- A new poll of $n = 50$ Floridians recorded $Y$, the number that support Michelle. 

    - The results depend upon $\pi$ -- the greater Michelle’s actual support, the greater $Y$ will tend to be. 
    
- To model the dependence of $Y$ on $\pi$, we assume

    - voters answer the poll independently of one another;
    - the probability that any polled voter supports your candidate Michelle is $\pi$
    
- This is a binomial event, $Y|\pi \sim \text{Bin}(50, \pi)$,  with conditional pmf, $f(y|\pi)$ defined for $y \in \{0, 1, ..., 50\}$

$$f(y|\pi) = P[Y = y|\pi] = {50 \choose y} \pi^y (1-\pi)^{50-y}$$

## The Binomial Data Model and Likelihood Function {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- The conditional pmf, $f(y|\pi)$, gives us answers to a hypothetical question:

    - If Michelle's support were given some value of $\pi$, then how many of the 50 polled voters ($Y=y$) might we expect to suppport her?

::: {.panel-tabset}

## Code

```{r}
#| eval: false

n <- 50
pi <- value of pi

binom_prob <- tibble(n_success = 1:n) %>%
  mutate(prob = dbinom(n_success, size=n, prob=pi))
binom_prob %>%
  ggplot(aes(x=n_success,y=prob))+
  geom_col(width=0.2)+
  labs(x= "Number of Successes",
       y= "Probability") +
  theme_bw()
```

## Code 1

```{r}
#| eval: false

n <- 50
pi <- 0.1

binom_prob <- tibble(n_success = 1:n) %>%
  mutate(prob = dbinom(n_success, size=n, prob=pi))
binom_prob %>%
  ggplot(aes(x=n_success,y=prob))+
  geom_col(width=0.2)+
  labs(x= "Number of Successes",
       y= "Probability") +
  theme_bw()
```

## Graph 1

<center>
```{r}
#| echo: false

n <- 50
pi <- 0.1

binom_prob <- tibble(n_success = 1:n) %>%
  mutate(prob = dbinom(n_success, size=n, prob=pi))
binom_prob %>%
  ggplot(aes(x=n_success,y=prob))+
  geom_col(width=0.2)+
  labs(x= "Number of Successes",
       y= "Probability") +
  theme_bw()
```
</center>

## Code 2

```{r}
#| eval: false

n <- 50
pi <- 0.5

binom_prob <- tibble(n_success = 1:n) %>%
  mutate(prob = dbinom(n_success, size=n, prob=pi))
binom_prob %>%
  ggplot(aes(x=n_success,y=prob))+
  geom_col(width=0.2)+
  labs(x= "Number of Successes",
       y= "Probability") +
  theme_bw()
```

## Graph 2

<center>
```{r}
#| echo: false

n <- 50
pi <- 0.5

binom_prob <- tibble(n_success = 1:n) %>%
  mutate(prob = dbinom(n_success, size=n, prob=pi))
binom_prob %>%
  ggplot(aes(x=n_success,y=prob))+
  geom_col(width=0.2)+
  labs(x= "Number of Successes",
       y= "Probability") +
  theme_bw()
```
</center>

## Code 3

```{r}
#| eval: false

n <- 50
pi <- 0.75

binom_prob <- tibble(n_success = 1:n) %>%
  mutate(prob = dbinom(n_success, size=n, prob=pi))
binom_prob %>%
  ggplot(aes(x=n_success,y=prob))+
  geom_col(width=0.2)+
  labs(x= "Number of Successes",
       y= "Probability") +
  theme_bw()
```

## Graph 3

<center>
```{r}
#| echo: false

n <- 50
pi <- 0.75

binom_prob <- tibble(n_success = 1:n) %>%
  mutate(prob = dbinom(n_success, size=n, prob=pi))
binom_prob %>%
  ggplot(aes(x=n_success,y=prob))+
  geom_col(width=0.2)+
  labs(x= "Number of Successes",
       y= "Probability") +
  theme_bw()
```
</center>

:::

## The Binomial Data Model and Likelihood Function {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- It is observed that $Y=30$ of the $n=50$ polled voters support Michelle.

- We now want to find the likelihood function -- remember that we treat $Y=30$ as the observed data and $\pi$ as unknown,

$$
\begin{align*}
f(y|\pi) &= {50 \choose y} \pi^y (1-\pi)^{50-y} \\
L(\pi|y=30) &= {50 \choose 30} \pi^{30} (1-\pi)^{20}
\end{align*}
$$

- This is valid for $\pi \in [0, 1]$.

## The Binomial Data Model and Likelihood Function {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- What is the likelihood of 30/50 voters supporting Michelle?

::: {.panel-tabset}

## Base Code

```{r}
#| eval: false
dbinom(30, 50, pi)
```

## Low $\pi$

- Let's assume $\pi = 0.25$,

```{r}
dbinom(30, 50, 0.25)
```

## Medium $\pi$

- Let's assume $\pi = 0.5$,

```{r}
dbinom(30, 50, 0.5)
```

## High $\pi$

- Let's assume $\pi = 0.75$,

```{r}
dbinom(30, 50, 0.75)
```

:::

## The Binomial Data Model and Likelihood Function {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- Challenge!

- Create a graph showing what happens to the likelihood for different values of $\pi$.

    - i.e., have $\pi$ on the $x$-axis and likelihood on the $y$-axis.
    
## The Binomial Data Model and Likelihood Function {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- Challenge!

::: {.panel-tabset}

## Code

```{r}
#| eval: false
graph <- tibble(pi = seq(0, 1, 0.001)) %>%
  mutate(likelihood = dbinom(30, 50, pi))

graph %>% ggplot(aes(x = pi, y = likelihood)) +
  geom_line() +
  labs(x = "Probability of Success", y = "Likelihood") +
  theme_bw()
```

## Graph

<center>
```{r}
#| echo: false
graph <- tibble(pi = seq(0, 1, 0.001)) %>%
  mutate(likelihood = dbinom(30, 50, pi))

graph %>% ggplot(aes(x = pi, y = likelihood)) +
  geom_line() +
  labs(x = "Probability of Success", y = "Likelihood") +
  theme_bw()
```
</center>


:::


## The Binomial Data Model and Likelihood Function {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- Where is the maximum?

<center>
```{r}
#| echo: false
graph <- tibble(pi = seq(0, 1, 0.001)) %>%
  mutate(likelihood = dbinom(30, 50, pi))

graph %>% ggplot(aes(x = pi, y = likelihood)) +
  geom_line() +
  labs(x = "Probability of Success", y = "Likelihood") +
  theme_bw()
```
</center>

## The Beta Posterior Model {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

$$
\begin{align*}
Y|\pi &\sim \text{Bin}(50, \pi) \\
\pi &\sim \text{Beta}(45, 55)
\end{align*}
$$

<center>
```{r}
#| echo: false
plot_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50, posterior = FALSE) + 
  theme_bw()
```
</center>

## The Beta Posterior Model {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

<center>
```{r}
#| echo: false
plot_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50, posterior = FALSE) + 
  theme_bw()
```
</center>

- The prior and data don't completely agree. 

- The prior is a bit more pessimistic about Michelle's election support than the data obtained from the latest poll.

## The Beta Posterior Model {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

:::{.panel-tabset}

## Code 

- To graph the posterior,

<center>
```{r}
#| eval: false
plot_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50) + 
  theme_bw()
```
</center>

## Graph 

<center>
```{r}
#| echo: false
plot_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50) + 
  theme_bw()
```
</center>

:::

## The Beta Posterior Model {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- We can see that the posterior model of $\pi$ is continuous and $\in [0, 1]$.

- The shape of the posterior appears to also have a Beta($\alpha$, $\beta$) model.

    - The shape parameters ($\alpha$ and $\beta$) have been *updated*.
    
- If we were to collect more information about Michelle's support, we would use the current posterior as the new prior, then update our posterior. 

    - How do we know what the updated parameters are?

```{r}
summarize_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50)
```

## The Beta-Binomial Model {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- We used Michelle's election support to understand the Beta-Binomial model.

- Let's now generalize it for any appropriate situation.

$$
\begin{align*}
Y|\pi &\sim \text{Bin}(n, \pi) \\
\pi &\sim \text{Beta}(\alpha, \beta) \\
\pi | (Y=y) &\sim \text{Beta}(\alpha+y, \beta+n-y)
\end{align*}
$$

- We can see that the posterior distribution reveals the influence of the prior ($\alpha$ and $\beta$) and data ($y$ and $n$).

## The Beta-Binomial Model {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- Let's pause and think about this from a theoretical standpoint.

- The Beta distribution is a *conjugate prior* for the likelihood.

    - **Conjugate prior**: the posterior is from the same model family as the prior.
    
- Recall the Beta prior, $f(\pi)$, 

$$ L(\pi|y) = {n \choose y} \pi^y (1-\pi)^{n-y} $$

- and the likelihood function, $L(\pi|y)$.

$$ f(\pi) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} \pi^{\alpha-1}(1-\alpha)^{\beta-1} $$

## The Beta-Binomial Model {background-image="/Users/sseals/Library/CloudStorage/GoogleDrive-sseals@uwf.edu/My Drive/00 - Personal/R/quarto themes/slide.png" background-size="contain"}

- We can put the prior and likelihood together to create the posterior,

$$
\begin{align*}
f(\pi|y) &\propto f(\pi)L(\pi|y) \\
&= \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} \pi^{\alpha-1}(1-\pi)^{\beta-1} \times {n \choose y} \pi^y (1-\pi)^{n-1} \\
&\propto \pi^{(\alpha+y)-1} (1-\pi)^{(\beta+n-y)-1}
\end{align*}
$$

- This is the same structure as the normalized Beta($\alpha+y, \beta+n-y$),

$$f(\pi|y) = \frac{\Gamma(\alpha+\beta+n)}{\Gamma(\alpha+y) \Gamma(\beta+n-y)} \pi^{(\alpha+y)-1} (1-\pi)^{(\beta+n-y)-1}$$

























